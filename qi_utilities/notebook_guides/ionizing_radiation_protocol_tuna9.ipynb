{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ionizing radiation burst detection in Tuna-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Authors:** Marios Samiotis (m.samiotis@tudelft.nl)\n",
    "\n",
    "**Date:** December 15, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will run the following cell in order to login to the Quantum Inspire platform. You will need an account in order to login to the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! qi login \"https://staging.qi2.quantum-inspire.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit_quantuminspire.qi_provider import QIProvider\n",
    "from qi_utilities.utility_functions.result_processing import return_raw_data\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Connect to the Quantum Inspire backend Tuna-9 in the staging environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first need to connect to the Quantum Inspire provider, by running the following cell,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider = QIProvider()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may see the full list of all available backends of Quantum Inspire platform by running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider.backends()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now connect to the backend Tuna-9 backend by running the following cell,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend_name = \"Tuna-9\"\n",
    "backend = provider.get_backend(name=backend_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Creating the detection circuit for Tuna-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_qubits = 9\n",
    "\n",
    "X_operation_duration = 0.02 # in [us]\n",
    "wait_time = 2 # in [us]\n",
    "readout_duration = 0.800 # in [us]\n",
    "cycle_time = 10 # in [us]\n",
    "idle_time = cycle_time - (X_operation_duration + wait_time + readout_duration)\n",
    "\n",
    "nr_measurements_per_circuit = 2**7\n",
    "nr_circuit_runs = 50 * 2**2\n",
    "job_limit = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc = QuantumCircuit(nr_qubits, nr_qubits * nr_measurements_per_circuit)\n",
    "\n",
    "CC_cycle_time = 0.02 # in [us]\n",
    "\n",
    "\n",
    "for repetition in range(nr_measurements_per_circuit):\n",
    "    for qubit_idx in range(nr_qubits):\n",
    "        qc.x(qubit_idx)\n",
    "    qc.barrier()\n",
    "    for qubit_idx in range(nr_qubits):\n",
    "        qc.delay(wait_time / CC_cycle_time, qubit_idx, unit='dt')\n",
    "    qc.barrier()\n",
    "    for qubit_idx in range(nr_qubits):\n",
    "        qc.measure(qubit = qubit_idx, cbit = qubit_idx + repetition*nr_qubits)\n",
    "    qc.barrier()\n",
    "    for qubit_idx in range(nr_qubits):\n",
    "        qc.delay(idle_time / CC_cycle_time, qubit_idx, unit='dt')\n",
    "    qc.barrier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import h5py\n",
    "import json\n",
    "import os\n",
    "\n",
    "def generate_hdf5_file(raw_data_list):\n",
    "\n",
    "    data_directory = r'/Users/mariossamiotis/Documents/Tuna9_cosmic_ray_data/'\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    timestamp = timestamp.split('_')\n",
    "\n",
    "    date_dir = os.path.join(data_directory, f\"{timestamp[0]}\")\n",
    "    if os.path.isdir(date_dir):\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(date_dir, exist_ok=False)\n",
    "\n",
    "    job_raw_data = []\n",
    "\n",
    "    for circuit_shot_idx in range(len(raw_data_list)):\n",
    "        ordered_shot_results = raw_data_list[circuit_shot_idx][::-1]\n",
    "        \n",
    "        for mst_block_idx in range(nr_measurements_per_circuit):\n",
    "            measurement_list = [127]\n",
    "            for qubit_idx in range(nr_qubits):\n",
    "                measurement_list.append(ordered_shot_results[qubit_idx + mst_block_idx * nr_qubits])\n",
    "            job_raw_data.append(measurement_list)\n",
    "\n",
    "    job_raw_data = np.array(job_raw_data, dtype=np.int8)\n",
    "\n",
    "    job_dir = os.path.join(date_dir, f\"{timestamp[1]}_XOR_{int(cycle_time)}_run\")\n",
    "    os.mkdir(job_dir)\n",
    "\n",
    "    hdf5_file_dir = os.path.join(job_dir, f\"{timestamp[1]}_XOR_{int(cycle_time)}_run.hdf5\")\n",
    "    with h5py.File(hdf5_file_dir, 'w') as file:\n",
    "        file.create_dataset('Experimental Data/Data', data=job_raw_data, compression=\"gzip\")\n",
    "\n",
    "    metadata_dict = {}\n",
    "    metadata_dict['data_timestamp'] = f\"{timestamp[0]}_{timestamp[1]}\"\n",
    "    metadata_dict['backend_name'] = backend_name\n",
    "    metadata_dict['nr_qubits'] = nr_qubits\n",
    "    metadata_dict['X_operation_duration [us]'] = X_operation_duration\n",
    "    metadata_dict['wait_time [us]'] = wait_time\n",
    "    metadata_dict['readout_duration [us]'] = readout_duration\n",
    "    metadata_dict['cycle_time [us]'] = cycle_time\n",
    "    metadata_dict['idle_time [us]'] = idle_time\n",
    "    metadata_dict['nr_measurements_per_circuit'] = nr_measurements_per_circuit\n",
    "    metadata_dict['nr_circuit_runs'] = nr_circuit_runs\n",
    "    metadata_dict['job_limit'] = job_limit\n",
    "\n",
    "    json_path = f\"{job_dir}/{timestamp[0]}_{timestamp[1]}_metadata.json\"\n",
    "    with open(json_path, 'w') as file:\n",
    "        json.dump(metadata_dict, file, indent=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Run the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for job_idx in tqdm(range(job_limit)):\n",
    "    try:\n",
    "        job = backend.run(qc, shots=nr_circuit_runs, memory = True)\n",
    "        result = job.result(timeout = 600)\n",
    "        raw_data_list = return_raw_data(qc, result)\n",
    "        \n",
    "        generate_hdf5_file(raw_data_list)\n",
    "    except:\n",
    "        print('Processor seems to be offline!')\n",
    "        time.sleep(600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantuminspire",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
